{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n",
        "\n",
        "Decision tree is a supervised machine learning algorithm which deals with both classification and regression tasks.\n",
        "It divides the data by asking yes/no question into homogeneous groups to take decisions.\n",
        "\n",
        "how  it work in the context of classification:-\n",
        "\n",
        "Step 1 - Start at the top root(the entire datasets is considered at the top)\n",
        "\n",
        "Step 2 - Choose the best feature to split :- the algorithm selects a best feature to split data into classes. This is based on criteria like:\n",
        "\n",
        "Gini Impurity\n",
        "\n",
        "Entropy / Information Gain\n",
        "\n",
        "Classification Error\n",
        "\n",
        "Step 3 :- Split the dataset :- split the data by asking yes/no question (eg.- age>30).\n",
        "\n",
        "Step 4:- Repeat for each subset.\n",
        "\n",
        "Step 5:- Stop Splitting (Leaf Nodes) :- When a stopping condition is met, a leaf node is created with a predicted class label.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2j0WUI7bYTUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures.\n",
        "How do they impact the splits in a Decision Tree?\n",
        "\n",
        "In Decision tree , impurity means how much data is mixed at a node. The goal of splitting is to reduce the impurity - to make child node as pure as possible.\n",
        "\n",
        "Two common impurity measures are :-  \n",
        "1. Gini Impurity :- Gini Impurity measures the probability of incorrectly classifying a randomly chosen element if it were randomly labeled according to the distribution of labels in the node.\n",
        "\n",
        "gini = 0 means node is pure.\n",
        "higher gini - more mixed class.\n",
        "\n",
        "2. Entropy impurity :- Entropy measures the amount of uncertainty or disorder in the data at a node.\n",
        "\n",
        "\n",
        "entropy = 0 means node is pure.\n",
        "Higher entropy ‚Üí higher disorder (more class mixture)\n",
        "\n",
        "**Impact the splits in a Decision Tree** :- Using this we calculate Information gain(entropy) to choose best feature to split data into same class.\n",
        "\n",
        "It helps to Helps pick the best split.\n",
        "\n"
      ],
      "metadata": {
        "id": "VcNhf1YnYR1M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision\n",
        "Trees? Give one practical advantage of using each.\n",
        "\n",
        "\n",
        "Pruning helps to reduce overfitting from the model by reducing their size.\n",
        "\n",
        "Two types of pruning are üá±\n",
        "1. Pre-Pruning :-\n",
        "\n",
        "a. It happens during the tree building process.\n",
        "\n",
        "b. It stops the tree from growing after a certain point of time.\n",
        "\n",
        "c. Example:- max_depth, min_samples_split, min_impurity_decrease\n",
        "\n",
        "d. The goal is to avoid large, complex tree.\n",
        "\n",
        "e. The advantages is that it fasters the model training.\n",
        "\n",
        "\n",
        "\n",
        "2. Post-Pruning :-\n",
        "\n",
        "a. It happens after the tree building process.\n",
        "\n",
        "b. Grows the tree full and then cut back its branches.\n",
        "\n",
        "c. Example:- Prune branches with low importance or accuracy.\n",
        "\n",
        "d. The goal is to remove that part of tree that doesn't improves accuracy.\n",
        "\n",
        "e. The advantages is that it gives better model acccuracy.\n"
      ],
      "metadata": {
        "id": "N_SDf9Z1YZV6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is Information Gain in Decision Trees, and why is it important for\n",
        "choosing the best split?\n",
        "\n",
        "\n",
        "Information Gain (IG) measures how much ‚Äúpurity‚Äù improves after making a split in a decision tree.\n",
        "\n",
        "It tells us how useful a feature is for splitting the data to classify it correctly.\n",
        "\n",
        "We use Information Gain ‚Äî it helps the tree choose the best feature by checking which one reduces the uncertainty (or \"impurity\") the most.\n",
        "\n",
        "#Why Is It Important?\n",
        "It guides the tree to make the most informative splits\n",
        "\n",
        "Helps the model learn faster and more accurately\n",
        "\n",
        "Prevents unnecessary or poor splits.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1j2Bj9SzYa1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some common real-world applications of Decision Trees, and\n",
        "what are their main advantages and limitations?\n",
        "\n",
        "\n",
        "#Some common real-world applications of Decision Trees are :-\n",
        "1. Finance\n",
        "\n",
        "Credit Risk Assessment: Predict if a person is likely to repay a loan.\n",
        "\n",
        "Fraud Detection: Detect suspicious transactions or patterns.\n",
        "\n",
        "2. Healthcare\n",
        "\n",
        "Disease Diagnosis: Predict whether a patient has a disease based on symptoms.\n",
        "\n",
        "Treatment Plans: Suggest treatments based on patient data.\n",
        "\n",
        "3. Marketing\n",
        "\n",
        "Customer Segmentation: Classify customers into groups (e.g., high/low value).\n",
        "\n",
        "Campaign Targeting: Predict who is likely to respond to a marketing campaign.\n",
        "\n",
        "4. E-commerce\n",
        "\n",
        "Product Recommendation: Suggest products based on past purchases or behavior.\n",
        "\n",
        "Churn Prediction: Predict which users are likely to stop using a service.\n",
        "\n",
        "5. Education\n",
        "\n",
        "Student Performance: Predict whether a student will pass/fail based on attendance, test scores, etc.\n",
        "\n",
        "# Main advantages:-\n",
        "1. Easy to Understand.\n",
        "2. No Need for Feature Scaling.\n",
        "3. Handles Both(numerical and categorical features) Types of Data.\n",
        "4. Captures complex patterns in the data.\n",
        "5. Fast to Train\n",
        "\n",
        "#Disadvantages :-\n",
        "1. Overfitting\n",
        "2. Unstable - Small changes in data can lead to very different trees.\n",
        "3. Bias Toward Features with More Levels\n",
        "4. Not Always Most Accurate"
      ],
      "metadata": {
        "id": "aS6odv7MYcZi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Question 6: Write a Python program to:\n",
        "‚óè Load the Iris Dataset\n",
        "‚óè Train a Decision Tree Classifier using the Gini criterion\n",
        "‚óè Print the model‚Äôs accuracy and feature importances\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "#Dataset\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "df['target'] = pd.Series(data.target)\n",
        "\n",
        "\n",
        "#split into X and Y\n",
        "X = df.drop('target', axis = 1)\n",
        "Y = df['target']\n",
        "\n",
        "#traintest split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)\n",
        "\n",
        "#model training\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(criterion = 'gini')\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#evaluation metrics\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "print(accuracy_score(Y_test, y_pred))\n",
        "print(model.feature_importances_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph92Z17yirge",
        "outputId": "48577a07-574a-4f4d-ef64-7420f942c578"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9333333333333333\n",
            "[0.         0.01879699 0.05690362 0.92429938]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Question 7: Write a Python program to:\n",
        "‚óè Load the Iris Dataset\n",
        "‚óè Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to\n",
        "a fully-grown tree.\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "#Dataset\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "df['target'] = pd.Series(data.target)\n",
        "\n",
        "\n",
        "#split into X and Y\n",
        "X = df.drop('target', axis = 1)\n",
        "Y = df['target']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)\n",
        "\n",
        "#model training\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(criterion = 'gini', max_depth = 3)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#evaluation metrics\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "print(f'Not fully grown {accuracy_score(Y_test, y_pred)}')\n",
        "\n",
        "\n",
        "#without max_depth\n",
        "#traintest split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)\n",
        "\n",
        "#model training\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier(criterion = 'gini')\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#evaluation metrics\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "fully_grown = (accuracy_score(Y_test, y_pred))\n",
        "\n",
        "print(f'Accuracy fully grown {fully_grown}')\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgeVD74Xmrt4",
        "outputId": "b0e3c642-51fc-403d-8207-9582ae7feb60"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Not fully grown 0.9666666666666667\n",
            "Accuracy fully grown 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Question 8: Write a Python program to:\n",
        "‚óè Load the California Housing dataset from sklearn\n",
        "‚óè Train a Decision Tree Regressor\n",
        "‚óè Print the Mean Squared Error (MSE) and feature importances\"\"\"\n",
        "\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "import pandas as pd\n",
        "\n",
        "data = fetch_california_housing()\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "df['target'] = pd.Series(data.target)\n",
        "\n",
        "#split into X and Y\n",
        "X = df.drop('target', axis = 1)\n",
        "Y = df['target']\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)\n",
        "\n",
        "#model training\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "model = DecisionTreeRegressor()\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#evaluation metrics\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "print(mean_squared_error(Y_test, y_pred))\n",
        "print(model.feature_importances_)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcLK6pTSo8ja",
        "outputId": "1e1a4225-61d5-4246-caf7-c3d77ab2f670"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5550035360897286\n",
            "[0.51844712 0.0520653  0.04952547 0.02591319 0.03047108 0.13225491\n",
            " 0.10034261 0.09098034]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Question 9: Write a Python program to:\n",
        "‚óè Load the Iris Dataset\n",
        "‚óè Tune the Decision Tree‚Äôs max_depth and min_samples_split using\n",
        "GridSearchCV\n",
        "‚óè Print the best parameters and the resulting model accuracy\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.datasets import  load_iris\n",
        "import pandas as pd\n",
        "\n",
        "data = load_iris()\n",
        "df = pd.DataFrame(data.data, columns = data.feature_names)\n",
        "df['target'] = pd.Series(data.target)\n",
        "\n",
        "#split into X and Y\n",
        "X = df.drop('target', axis = 1)\n",
        "Y = df['target']\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 2)\n",
        "\n",
        "#model train\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "model = DecisionTreeClassifier()\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, 6],\n",
        "    'min_samples_split': [2, 4, 6, 8]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(model, param_grid, cv = 5)\n",
        "grid_search.fit(X_train, Y_train)\n",
        "\n",
        "y_pred = grid_search.predict(X_test)\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print( accuracy_score(Y_test, y_pred))\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_estimator_.predict(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4x272XYqyTg",
        "outputId": "f9372adc-11a8-4129-b11e-466f18a85e2a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9333333333333333\n",
            "{'max_depth': 5, 'min_samples_split': 2}\n",
            "[0 0 2 0 0 1 0 2 2 0 0 0 0 0 1 1 0 1 2 1 2 1 2 1 1 0 0 2 0 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you‚Äôre working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "Explain the step-by-step process you would follow to:\n",
        "‚óè Handle the missing values\n",
        "‚óè Encode the categorical features\n",
        "‚óè Train a Decision Tree model\n",
        "‚óè Tune its hyperparameters\n",
        "‚óè Evaluate its performance\n",
        "And describe what business value this model could provide in the real-world\n",
        "setting.\n",
        "\n",
        "\n",
        "#Step-by-step process  to be followed:-\n",
        "\n",
        "‚óè Handle the missing values :- Numerical columns: Fill with mean or median\n",
        "\n",
        "Categorical columns: Fill with mode or a placeholder like \"Unknown\".\n",
        "\n",
        "‚óè Encode the categorical features :- Use Label Encoding for ordinal or binary categories\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "df['gender'] = LabelEncoder().fit_transform(df['gender'])\n",
        "\n",
        "\n",
        "‚óè Train a Decision Tree model :-\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "*Split the data\n",
        "X = df.drop('disease', axis=1)\n",
        "y = df['disease']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        " *Train the model\n",
        "model = DecisionTreeClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "‚óè Tune its hyperparameters :- Prevent overfitting and improve performance.\n",
        "Use GridSearchCV to tune:\n",
        "\n",
        "max_depth\n",
        "\n",
        "min_samples_split\n",
        "\n",
        "criterion (e.g., \"gini\", \"entropy\")\n",
        "\n",
        "‚óè Evaluate its performance\n",
        "\n",
        "üîß Use:\n",
        "\n",
        "Accuracy\n",
        "\n",
        "Precision & Recall (important for medical context)\n",
        "\n",
        "F1 Score\n",
        "\n",
        "Confusion Matrix\n",
        "\n",
        "ROC-AUC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"ROC-AUC Score:\", roc_auc_score(y_test, best_model.predict_proba(X_test)[:,1]))\n",
        "\n",
        "\n",
        "# Business value this model could provide in the real-world setting.\n",
        "A well-built model could save lives, optimize care, and reduce healthcare costs.\n",
        "\n",
        "1. Early Detection  - Identify patients at risk before symptoms get worse\n",
        "2. Personalized Treatment - Help doctors decide who needs urgent care vs. monitoring.\n",
        "3. Cost Reduction\n",
        "4. Data-Driven Decisions\n"
      ],
      "metadata": {
        "id": "iYc_HdZts5bM"
      }
    }
  ]
}